{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Compose, Normalize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "\n",
    "from stepbystep.v0 import StepByStep\n",
    "from data_generation.image_classification import generate_dataset\n",
    "from helpers import index_splitter, make_balanced_sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 6, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_mat = np.array(\n",
    "    [[[\n",
    "        [1, 5, 6, 8, 11, 2],\n",
    "        [2, 5, 6, 8, 9, 3],\n",
    "        [0, 3, 16, 24, 2, 8],\n",
    "        [10, 21, 4, 69, 2, 3],\n",
    "        [33, 25, 5, 8, 9, 11],\n",
    "        [3, 8, 9, 3, 4, 7]\n",
    "    ]]]\n",
    ")\n",
    "\n",
    "image_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 3, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_mat = np.array(\n",
    "    [[[\n",
    "        [0, 0, 0],\n",
    "        [0, 1, 0],\n",
    "        [0, 0, 0]\n",
    "    ]]]\n",
    ")\n",
    "\n",
    "filter_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  6.,  8.,  9.],\n",
       "          [ 3., 16., 24.,  2.],\n",
       "          [21.,  4., 69.,  2.],\n",
       "          [25.,  5.,  8.,  9.]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor = torch.as_tensor(image_mat).float()\n",
    "filter_tensor = torch.as_tensor(filter_mat).float()\n",
    "\n",
    "concolved = F.conv2d(image_tensor, filter_tensor, stride=1)\n",
    "concolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ -4.9234,  -9.3491,  -7.3900,  -7.7206],\n",
       "          [ -6.0504, -27.8258, -10.3816, -18.9732],\n",
       "          [-16.9247,  -5.8056,  -5.2243,  -1.2503],\n",
       "          [ -0.1438,  -5.3850,   9.9900,   3.3429]]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv2d(\n",
    "    in_channels=1, out_channels=1, kernel_size=3, stride=1\n",
    ")\n",
    "\n",
    "conv(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-0.2542,  0.0047, -0.1818],\n",
       "          [-0.1648, -0.0099, -0.1213],\n",
       "          [ 0.2483, -0.1855, -0.2277]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1880, -0.0903,  0.1902],\n",
       "          [-0.0716,  0.3158,  0.2549],\n",
       "          [ 0.0767,  0.1675,  0.1331]]]], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_multi = nn.Conv2d(\n",
    "    in_channels=1, out_channels=2, kernel_size=3, stride=1\n",
    ")\n",
    "\n",
    "conv_multi.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  6.,  8.,  9.],\n",
       "          [ 3., 16., 24.,  2.],\n",
       "          [21.,  4., 69.,  2.],\n",
       "          [25.,  5.,  8.,  9.]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    conv.weight[0] = filter_tensor\n",
    "    conv.bias[0] = 0\n",
    "\n",
    "conv(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  1.,  5.,  6.,  8., 11.,  2.,  0.],\n",
       "          [ 0.,  2.,  5.,  6.,  8.,  9.,  3.,  0.],\n",
       "          [ 0.,  0.,  3., 16., 24.,  2.,  8.,  0.],\n",
       "          [ 0., 10., 21.,  4., 69.,  2.,  3.,  0.],\n",
       "          [ 0., 33., 25.,  5.,  8.,  9., 11.,  0.],\n",
       "          [ 0.,  3.,  8.,  9.,  3.,  4.,  7.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_pad = nn.ConstantPad2d(padding=1, value=0)\n",
    "padded_image = conv_pad(image_tensor)\n",
    "padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  1.,  5.,  6.,  8., 11.,  2.,  0.],\n",
       "          [ 0.,  2.,  5.,  6.,  8.,  9.,  3.,  0.],\n",
       "          [ 0.,  0.,  3., 16., 24.,  2.,  8.,  0.],\n",
       "          [ 0., 10., 21.,  4., 69.,  2.,  3.,  0.],\n",
       "          [ 0., 33., 25.,  5.,  8.,  9., 11.,  0.],\n",
       "          [ 0.,  3.,  8.,  9.,  3.,  4.,  7.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_pad = F.pad(image_tensor, pad=(1, 1, 1, 1), mode='constant', value=0)\n",
    "f_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.,  1.,  5.,  6.,  8., 11.,  2.,  2.],\n",
       "          [ 1.,  1.,  5.,  6.,  8., 11.,  2.,  2.],\n",
       "          [ 2.,  2.,  5.,  6.,  8.,  9.,  3.,  3.],\n",
       "          [ 0.,  0.,  3., 16., 24.,  2.,  8.,  8.],\n",
       "          [10., 10., 21.,  4., 69.,  2.,  3.,  3.],\n",
       "          [33., 33., 25.,  5.,  8.,  9., 11., 11.],\n",
       "          [ 3.,  3.,  8.,  9.,  3.,  4.,  7.,  7.],\n",
       "          [ 3.,  3.,  8.,  9.,  3.,  4.,  7.,  7.]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_rep_pad = nn.ReplicationPad2d(padding=1)\n",
    "conv_rep_pad(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.,  1.,  5.,  6.,  8., 11.,  2.,  2.],\n",
       "          [ 1.,  1.,  5.,  6.,  8., 11.,  2.,  2.],\n",
       "          [ 2.,  2.,  5.,  6.,  8.,  9.,  3.,  3.],\n",
       "          [ 0.,  0.,  3., 16., 24.,  2.,  8.,  8.],\n",
       "          [10., 10., 21.,  4., 69.,  2.,  3.,  3.],\n",
       "          [33., 33., 25.,  5.,  8.,  9., 11., 11.],\n",
       "          [ 3.,  3.,  8.,  9.,  3.,  4.,  7.,  7.],\n",
       "          [ 3.,  3.,  8.,  9.,  3.,  4.,  7.,  7.]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_rep_pad = F.pad(image_tensor, pad=(1, 1, 1, 1), mode='replicate')\n",
    "f_rep_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  2.,  5.,  6.,  8.,  9.,  3.,  9.],\n",
       "          [ 5.,  1.,  5.,  6.,  8., 11.,  2., 11.],\n",
       "          [ 5.,  2.,  5.,  6.,  8.,  9.,  3.,  9.],\n",
       "          [ 3.,  0.,  3., 16., 24.,  2.,  8.,  2.],\n",
       "          [21., 10., 21.,  4., 69.,  2.,  3.,  2.],\n",
       "          [25., 33., 25.,  5.,  8.,  9., 11.,  9.],\n",
       "          [ 8.,  3.,  8.,  9.,  3.,  4.,  7.,  4.],\n",
       "          [25., 33., 25.,  5.,  8.,  9., 11.,  9.]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_ref_pad = nn.ReflectionPad2d(padding=1)\n",
    "conv_ref_pad(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  2.,  5.,  6.,  8.,  9.,  3.,  9.],\n",
       "          [ 5.,  1.,  5.,  6.,  8., 11.,  2., 11.],\n",
       "          [ 5.,  2.,  5.,  6.,  8.,  9.,  3.,  9.],\n",
       "          [ 3.,  0.,  3., 16., 24.,  2.,  8.,  2.],\n",
       "          [21., 10., 21.,  4., 69.,  2.,  3.,  2.],\n",
       "          [25., 33., 25.,  5.,  8.,  9., 11.,  9.],\n",
       "          [ 8.,  3.,  8.,  9.,  3.,  4.,  7.,  4.],\n",
       "          [25., 33., 25.,  5.,  8.,  9., 11.,  9.]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_ref_pad = F.pad(image_tensor, pad=(1, 1, 1, 1), mode='reflect')\n",
    "f_ref_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 7.,  3.,  8.,  9.,  3.,  4.,  7.,  3.],\n",
       "          [ 2.,  1.,  5.,  6.,  8., 11.,  2.,  1.],\n",
       "          [ 3.,  2.,  5.,  6.,  8.,  9.,  3.,  2.],\n",
       "          [ 8.,  0.,  3., 16., 24.,  2.,  8.,  0.],\n",
       "          [ 3., 10., 21.,  4., 69.,  2.,  3., 10.],\n",
       "          [11., 33., 25.,  5.,  8.,  9., 11., 33.],\n",
       "          [ 7.,  3.,  8.,  9.,  3.,  4.,  7.,  3.],\n",
       "          [ 2.,  1.,  5.,  6.,  8., 11.,  2.,  1.]]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_cir_pad = F.pad(image_tensor, pad=(1, 1, 1, 1), mode='circular')\n",
    "f_cir_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.,  5.,  6.,  8., 11.,  2.],\n",
       "          [ 2.,  5.,  6.,  8.,  9.,  3.],\n",
       "          [ 0.,  3., 16., 24.,  2.,  8.],\n",
       "          [10., 21.,  4., 69.,  2.,  3.],\n",
       "          [33., 25.,  5.,  8.,  9., 11.],\n",
       "          [ 3.,  8.,  9.,  3.,  4.,  7.]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_image = F.conv2d(f_cir_pad, filter_tensor, stride=1)\n",
    "conv_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  8., 11.],\n",
       "          [21., 69.,  8.],\n",
       "          [33.,  9., 11.]]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_image = F.max_pool2d(conv_image, kernel_size=2)\n",
    "pooled_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[69.]]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_pool = nn.MaxPool2d(kernel_size=4)\n",
    "nn_pool(conv_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 4.8889,  9.0000, 10.0000,  8.3333],\n",
       "          [ 7.4444, 17.3333, 15.5556, 14.2222],\n",
       "          [13.0000, 19.4444, 15.4444, 15.1111],\n",
       "          [13.1111, 16.8889, 12.5556, 12.8889]]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_image2 = F.avg_pool2d(conv_image, kernel_size=3, stride=1)\n",
    "pooled_image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[11.7500, 12.4375, 11.3125],\n",
       "          [14.9375, 13.5000, 11.6875],\n",
       "          [15.0625, 13.2500, 11.5000]]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_pool = nn.AvgPool2d(kernel_size=4, stride=1)\n",
    "nn_pool(conv_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  8., 11., 21., 69.,  8., 33.,  9., 11.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Flatten()(pooled_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  8., 11., 21., 69.,  8., 33.,  9., 11.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_image.view(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
